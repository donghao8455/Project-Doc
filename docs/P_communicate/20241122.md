## 2024/11/22 第三次交流

吴老师，我这段时间主要看了一些跨模态对齐相关的文章，梳理了一些有代表性的对比模型和问题，主要涉及到模态间的对齐方法、特征间的模态融合和对不同数据模态的特征提取

可借鉴的对比模型：

- **模态间的对齐**，在`BLIP-2`大模型中，使用了`Q-Former`（`Query Transformer`）来弥补模态间的差距，实现了特征的对齐，具体而言就是一个模态提供Q，另一个模态提供K和V，对齐实现方式是通过一个模态的K和V去查找另一个模态的Q（这种对齐方式是一个全局上的模态对齐，但是忽略了模态间的时间特性）

- `AlignVSR`模型用来对齐视频模态的数据和音频模态的数据，采用了全局的对齐和局部的对齐方式：

  ![image-20241121110434214](..\assets\image-20241121110434214.png)

  - 全局对齐（类似于`Q-Former`的方式）：对准的实现从每个视频帧到音频单元组的交叉注意力过程，即视频特征是查询（Q），而音频单元作用键（K）和值（V），这种对齐是全局的对齐，视频可以与任何音频单元进行对齐（为了更好地保留视频的时间信息，在视频特征中必须涉及位置编码）
  - 局部对齐：全局对齐不利用音频和视频模态之间的时间对齐，因此设计了局部对齐机制来解决这个问题，图中u表示音频单元经量化的数目，v表示视频特征序列，a表示音频特征序列（由于采样频率不同，一个视频帧对应三个音频帧），T表示是视频帧的总数

- 对于**模态间特征的融合**，在一篇情感分析的文章里面，提出了一种基于`Transformer-Encoder`的多层融合模型，利用多方向自注意的思想实现了文本和图像的标记级特征的对齐和融合，并利用`MLF`进行特征融合，从而提高了模型的抽象能力

  ![image-20241119160843178](..\assets\image-20241119160843178-1732265824593-1.png)

  `MLF`多层融合模块，使用文本（`BERT`）-图像（`ResNet`）编码器来获得文本和图像的隐藏表示（提取特征），之后需要将图像特征的维度转化为与文本特征相同的维度，将图像特征输入到基于多层`Transformer-Encoder`的图像`Transformer`层，得到图像序列特征的最终编码

  对于特征的融合，将文本的特征与图像序列特征连接起来，再使用一个多层变换器编码器作为文本图像融合层，对齐和融合多模态特征，得到文本和图像的融合序列特征

  ![image-20241120100248113](..\assets\image-20241120100248113.png)

  在获得了文本和图像融合的序列特征后，序列特征不能用于分类任务，因此，我们使用一个简单的注意力层来获得多模态表示

  这个模型中还提出了基于标签的对比学习（`LBCL`）和基于数据的对比学习任务（`DBCL`），其中基于标签的对比学习我认为是可以进行借鉴的：

  文章中的基于标签的对比学习，是根据情感标签将每个批次中的数据分为正面和负面示例，对于多模态数据的负标签，批次中具有相同负标签的数据作为正例（粉红色的正方形），而没有负标签的数据作为负例（灰色的正方形），该算法主要包括两个步骤：第一步是根据批量中的数据标签生成去掩码标签；第二步是计算损失矩阵，利用去掩码标签和损失矩阵得到最终的损失

  **结合基于标签的对比学习，我觉得可以把标签的思想使用到镁化炉中，镁化炉中有label数据，标记了正常和异常状态：正常状态（0）和异常状态（1）通过进行特征融合`MLF`多层融合模型，时序电流的特征为T，视频模态的特征为I，最后计算标记对比学习损失**

- **对于不同模态数据的特征提取**，`OneLLM`大模型是一种使用统一框架将八种模态与语言相结合的`MLLM`，通过一个统一的多模式编码器和一个渐进的多模式对齐管道来实现这一点

  ![image-20241122181748879](..\assets\image-20241122181748879.png)

  上图为`OneLLM`架构，该架构由模态标记化器、通用编码器、通用投影模块（`UPM`）和`LLM`组成，其中：

  - 模态标记器是`2D/1D`卷积层，用于将输入信号变换成标记序列

  - **通用编码器`Universal Encoder`**是用于提取高维特征的冻结视觉语言模型

    使用`CLIPViT`作为通用计算引擎，对于视频信号，将所有视频帧并行送入编码器，并在帧之间执行令牌式平均以加快训练，对于标记拼接，可以进一步增强模型的视频理解能力

  - `UPM`由几个投影专家和模态路由器组成，以将输入信号与语言对齐。对于对齐阶段，训练模态标记器和`UPM`，并保持`LLM`冻结

问题：

- 对于多模态对齐方面的文章，感觉很多文章中都是基于大模型来实现的（基于这些大模型做下游任务），这些预训练好的大模型涉及到的数据集都是非常庞大的，而且算力的要求也是非常大的

  我觉得基于镁化炉数据集做出来的对齐模型是不是通用性没有这么好？（做出来的对比模型可能只是适用这个特定的数据集，感觉如果使用镁化炉的数据来进行对齐好像有点过于单薄，但是如果加一点公开的数据进行对比实验，类似的视频-时序电流模态的公开数据集不太好找，如果使用图片-文本的数据集来进行后续设计的模型的对比实验，感觉有点不搭，思路有点卡壳，希望老师可以指点一下）

- 对比学习要实现效果好，需要满足两个条件：1、负例要尽可能的多；2、负例要尽可能一致，我们的数据集应该如何有效的进行构建负例？什么样的模态特征可以算作一个正例？（视频区域的`rgb`颜色变黄/白和三相电流忽然大幅度升高/三相电流的三相数据差异较大）

***

交流反馈：

- 继续去了解情感分析那篇文章中的研究方法

- 不用考虑通用性，基于镁化炉的数据集做这个工业背景下的专项研究

- 采用特征拉远拉近的方式进行对比学习
- 数据集中的电流异常表现机理是：电流数据变化较小的说明发生了异常，电流数据变化较大的表示镁化炉正在工作（正常工作的情况下，电流变化是比较大的）这一点与之前的理解是有偏差的

