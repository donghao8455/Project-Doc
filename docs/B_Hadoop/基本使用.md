## 基本使用

### 启动`hadoop`集群

首次启动`Hadoop`集群时，需要先在`Master`节点执行名称节点的格式化（只需要执行这一次，后面再启动`Hadoop`时，不要再次格式化名称节点），命令如下：

```txt
cd /usr/local/hadoop-3.3.6
./bin/hdfs namenode -format
```

启动`Hadoop`，启动需要在`Master`节点上进行，执行如下命令：（后续启动`Master`节点都需要运行）

```txt
cd /usr/local/hadoop-3.3.6
./sbin/start-dfs.sh
./sbin/start-yarn.sh
./sbin/mr-jobhistory-daemon.sh start historyserver
```

通过命令`jps`可以查看各个节点所启动的进程，`Master`节点和`Slave`节点都要看，在`cd /usr/local/hadoop-3.3.6`路径下输入`jps`命令

另外还需要在`Master`节点上通过“”查看数据节点是否正常启动：

```txt
cd /usr/local/hadoop-3.3.6
./bin/hdfs dfsadmin -report
```

如果集群以前能启动，但后来启动不了，特别是数据节点无法启动，不妨试着删除所有节点（包括`Slave`节点）上的`“/usr/local/hadoop-3.3.6/tmp”`文件夹，再重新执行一次`“hdfs namenode -format”`，再次启动即可

***

### 执行分布式实例

执行分布式实例，首先创建`HDFS`上的用户目录，可以在`Master`节点`（hadoopMaster）`上执行如下命令：

```txt
echo $PATH | tr ':' '\n'   #  查看PATH变量是否配置成功
hdfs dfs -mkdir -p /user/hadoop   #  此前已经配置了PATH环境变量，所以不用路径全称
hdfs dfs -ls /user       #  查看是否创建成功
```

然后，在`HDFS`中创建一个`input`目录，并把`“/usr/local/hadoop-3.3.6/etc/hadoop”`目录中的配置文件作为输入文件复制到`input`目录中，命令如下：

```txt
hdfs dfs -mkdir input
hdfs dfs -put /usr/local/hadoop-3.3.6/etc/hadoop/*.xml input
```

接着就可以运行 `MapReduce` 作业了，命令如下：

```txt
hadoop jar /usr/local/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar grep input output 'dfs[a-z.]+'
```

可以在`http://192.168.0.99:8088/cluster`中进行查看进度

查看输出结果：`hdfs dfs -cat output/*`

***

### 关闭`hadoop`集群

最后，关闭`Hadoop`集群，需要在`Master`节点`（hadoopMaster）`执行如下命令：

```txt
stop-yarn.sh
stop-dfs.sh
mr-jobhistory-daemon.sh stop historyserver
```

***

### `Web`总览

访问控制总览`web`：`http://192.168.0.99:9870`